


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Statistical Models for Series Forecasting &mdash; Predictability Crawler 1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/jquery.fancybox.min.css" type="text/css" />
  
    <link rel="stylesheet" href="../_static/glpi.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Predictability Crawler 1 documentation" href="../index.html"/>
        <link rel="next" title="Predictability Scoring Function" href="../scoringfunction/scoringfunction.html"/>
        <link rel="prev" title="Simulating Random and Predictable Signals" href="../simulating/simulating.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Predictability Crawler
          

          
          </a>

          
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Use the code:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../setup/setup.html">Setting Up the Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../simulating/simulating.html">Simulating Random and Predictable Signals</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Statistical Models for Series Forecasting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#preparing-feature-target-matrices">Preparing Feature &amp; Target Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="#statistical-learning-models">Statistical Learning Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loss-functions">Loss functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#statistical-models">Statistical Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#random-forests">Random Forests</a></li>
<li class="toctree-l4"><a class="reference internal" href="#lasso">LASSO</a></li>
<li class="toctree-l4"><a class="reference internal" href="#xgboost">XGBoost</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#data-treatment-pipeline">Data Treatment Pipeline</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#data-transforms">Data Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pipeline-methods">Pipeline Methods</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#putting-it-all-together">Putting it all Together</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../scoringfunction/scoringfunction.html">Predictability Scoring Function</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Predictability Crawler</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Statistical Models for Series Forecasting</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/models/models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <div class="rst-breadcrumbs-buttons" role="navigation" aria-label="breadcrumb navigation">
      
        <a href="../scoringfunction/scoringfunction.html" class="btn btn-neutral float-right" title="Predictability Scoring Function" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../simulating/simulating.html" class="btn btn-neutral" title="Simulating Random and Predictable Signals" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
  </div>
  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="statistical-models-for-series-forecasting">
<h1>Statistical Models for Series Forecasting<a class="headerlink" href="#statistical-models-for-series-forecasting" title="Permalink to this headline">¶</a></h1>
<p>The PCrawl library has a simple but extensible collection of statistical learning
models to be used for predition. This section describes how to use the simulations
to test those models, and how they are structered.</p>
<div class="section" id="preparing-feature-target-matrices">
<h2>Preparing Feature &amp; Target Matrices<a class="headerlink" href="#preparing-feature-target-matrices" title="Permalink to this headline">¶</a></h2>
<p>The PCrawl assumes a Feature &amp; Target Matrices representation. This means that information about
the simulated time series up to instant t has to be embedded in a vector. A simple approach
is to use the last <span class="math notranslate nohighlight">\(n\)</span> observations as a vector, a window summarizing past information.
The target to be infered from this set is the next value of the series. Once the windowsize
has been settled, it is easy to transform the simulation data into a Feature, Target, and Reference
matrices:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">using</span> <span class="n">PCrawl</span>

<span class="n">simulation</span> <span class="o">=</span> <span class="p">[</span><span class="n">wn</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span><span class="n">ar1</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span><span class="n">wn</span><span class="p">(</span><span class="mi">200</span><span class="p">)]</span>
<span class="n">windowsize</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">reference</span> <span class="o">=</span> <span class="n">make_x_y_ref</span><span class="p">(</span><span class="n">simulation</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="statistical-learning-models">
<h2>Statistical Learning Models<a class="headerlink" href="#statistical-learning-models" title="Permalink to this headline">¶</a></h2>
<p>In order to train a model, it is necessary to define some entities.</p>
<ul class="simple">
<li><p>The Loss function</p></li>
<li><p>The Statistical Model</p></li>
<li><p>The Processing Pipeline</p></li>
</ul>
<p>Well see how the PCrawl defines each one of those entities.</p>
<div class="section" id="loss-functions">
<h3>Loss functions<a class="headerlink" href="#loss-functions" title="Permalink to this headline">¶</a></h3>
<p>Loss functions define the numeric quantity to be minimized during the training. Although the PCrawl
admits both loss functions for Regression and Classification, only regression loss functions are currently
avaible. Defining a new loss is very straightfoward, it just needs to be function that receives two target matrices
(y and y_hat) and output a number representing how close they are according to the chosen method.
Example regressions loss functions are:</p>
<dl class="py function">
<dt id="mae">
<code class="sig-name descname">mae</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_hat</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mae" title="Permalink to this definition">¶</a></dt>
<dd><p>returns <span class="math notranslate nohighlight">\(\frac{1}{n}  \sum_{i=1}^{n} |y_{hat} - y|\)</span></p>
</dd></dl>

<dl class="py function">
<dt id="rmae">
<code class="sig-name descname">rmae</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_hat</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="headerlink" href="#rmae" title="Permalink to this definition">¶</a></dt>
<dd><p>returns <span class="math notranslate nohighlight">\(\frac{\frac{1}{n}  \sum_{i=1}^{n} |y_{hat} - y|}{\frac{1}{n} \sum_{i=1}^{n} |y|}\)</span></p>
<p>obs: when y and y_hat are innovations, the rmae is equivalent to the MASE of the integrated series</p>
</dd></dl>

<dl class="py function">
<dt id="mse">
<code class="sig-name descname">mse</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_hat</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mse" title="Permalink to this definition">¶</a></dt>
<dd><p>returns <span class="math notranslate nohighlight">\(\frac{1}{n}  \sum_{i=1}^{n} (y_{hat} - y)^{2}\)</span></p>
</dd></dl>

<dl class="py function">
<dt id="rmse">
<code class="sig-name descname">rmse</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_hat</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="headerlink" href="#rmse" title="Permalink to this definition">¶</a></dt>
<dd><p>returns <span class="math notranslate nohighlight">\(\sqrt{\frac{1}{n}  \sum_{i=1}^{n} (y_{hat} - y)^{2}}\)</span></p>
</dd></dl>

<p>All loss functions are located at Utils/lossfunctions.jl</p>
</div>
<div class="section" id="statistical-models">
<h3>Statistical Models<a class="headerlink" href="#statistical-models" title="Permalink to this headline">¶</a></h3>
<p>The PCrawls models make use of the Julia Language inheritance capability. They all inherit from
a abstract base class Abstract model. This class defines a interface of methods every model have
to implement  in order to function. (In Julia, the ! at the end of a function means that the function
alters one of the parameters given, and the &lt;: symbol means that the parameter is a class inherited
from the specifed type). Those methods are:</p>
<dl class="py function">
<dt id="trainmodel">
<code class="sig-name descname">trainmodel</code><span class="sig-paren">(</span><em class="sig-param">model&lt;:AbstractModel</em>, <em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="headerlink" href="#trainmodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the model passed (altering the object) to fit the features x to the target y.</p>
</dd></dl>

<dl class="py function">
<dt id="modelpredict">
<code class="sig-name descname">modelpredict</code><span class="sig-paren">(</span><em class="sig-param">model&lt;:AbstractModel</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#modelpredict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the model to predict targets based on the features x. Returns the predicted targets</p>
</dd></dl>

<p>Every model class has a internal dict named meta, where model parameters are stored.
Apart from the above functions, every models implements a custom form o hyperparmeter tunning,
and model specif methods, such as returning feature importances.
The statistical models implemented are RandomForest, the Gradient Boosting Model, and the LASSO.</p>
<div class="section" id="random-forests">
<h4>Random Forests<a class="headerlink" href="#random-forests" title="Permalink to this headline">¶</a></h4>
<p>The hyper-parameter tunning implemented for the Random Forests model is</p>
<dl class="py function">
<dt>
<code class="sig-name descname">rfgridmodel(x, y, [depths=[2, 3, 4, 5], portions=[.3, .4, .5, .6, .7, .8, .9],</code></dt>
<dt>
<code class="sig-name descname">nfeatures=[5, 10, 15, 20], ntrees=10])</code></dt>
<dd><p>Performs a grid search to determine the depth of the trees, the bootstraped portion of the
dataset, and the number of features to use at each tree. The search optimizes the in-sample
loss for data set (x, y).</p>
<p>Return a dict of params that can be used as the model meta.</p>
</dd></dl>

<p>The Random Forest model is located at Learning/randomforests.jl</p>
</div>
<div class="section" id="lasso">
<h4>LASSO<a class="headerlink" href="#lasso" title="Permalink to this headline">¶</a></h4>
<p>The hyper-parameter tunning implemented for the LASSO model is:</p>
<dl class="py function">
<dt>
<code class="sig-name descname">setlambda!(model, x, y)</code></dt>
<dd><p>Uses the BIC loss criterion to determine the <span class="math notranslate nohighlight">\(\lambda\)</span> to be used used in the model.
This function is also used inside the trainmodel! function for the LASSO. But it can be choosen
to use a pre-defined <span class="math notranslate nohighlight">\(\lambda\)</span> to train</p>
</dd></dl>

<p>The LASSO model also has a convinience function</p>
<dl class="py function">
<dt id="lassobic">
<code class="sig-name descname">lassobic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="headerlink" href="#lassobic" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a trained LASSO with <span class="math notranslate nohighlight">\(\lambda\)</span> the BIC criterion and on the dataset.</p>
</dd></dl>

<p>Once the LASSO model is trained, a number of functions can be used to extract information from it.
Some examples are:</p>
<dl class="py function">
<dt id="lambda">
<code class="sig-name descname">lambda</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambda" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the <span class="math notranslate nohighlight">\(\lambda\)</span> function of the model</p>
</dd></dl>

<dl class="py function">
<dt id="coefs">
<code class="sig-name descname">coefs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coefs" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the coefficients of the adjusted regression</p>
</dd></dl>

<p>These and others can be found at Learning/lasso.jl</p>
</div>
<div class="section" id="xgboost">
<h4>XGBoost<a class="headerlink" href="#xgboost" title="Permalink to this headline">¶</a></h4>
<p>The XGBoost is the gradient boosting implemented by the XGBoost library.
The hyper-parameter tunning implemented for the XGBoost model is</p>
<dl class="py function">
<dt>
<code class="sig-name descname">gridoptmodel(x, y, [depths=[2, 3, 4, 5, 6], etas=[.3, .4, .5, .6, .7, .8], subs=[.3, .4, .5, .6, .7, .8]],</code></dt>
<dt>
<code class="sig-name descname">nr_rounds)</code></dt>
<dd><p>Perform a grid-search to choose the depths of the trees, the normalizing eta parameterer, and the
amount of sub-sampling to use a each stage. The choice is made to minimize the in-sample error in the
dataset (x, y) when training with nr_rounds trees.</p>
<p>Returns a params dict that can be used as a meta to the XGBoost model.</p>
</dd></dl>

<p>The above function can help determine all hyper-parameters except for the number of trees,
which is very important. To do that, the model implements</p>
<dl class="py function">
<dt id="earlystopcv">
<code class="sig-name descname">earlystopcv</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">nr_round</em>, <em class="sig-param">pipeline::Pipeline</em><span class="sig-paren">)</span><a class="headerlink" href="#earlystopcv" title="Permalink to this definition">¶</a></dt>
<dd><p>This function Plots the evolution of the cross-validated loss function error from the
pipeline (see section below) containig a XGBoost model when the number of
trees grows from 1 to nr_round, and can be used to determine the optimal number of rounds to use.</p>
</dd></dl>

<p>Besides hyper-parameter tunning, the XGBoost model is capable of estimating a relative feature importance.
To use this capability as a feature-selection scheme, the code implements</p>
<dl class="py function">
<dt id="topfeatures">
<code class="sig-name descname">topfeatures</code><span class="sig-paren">(</span><em class="sig-param">xmat</em>, <em class="sig-param">y</em><span class="optional">[</span>, <em class="sig-param">nrfeatures=20</em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#topfeatures" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a feature matrix xmat, return only the columns refering the the top nrfeatures,
according to the feature importance of a XGBoost model with default hyperparameters
trained to minimize the rmae loss function adjusting xmat to y.</p>
</dd></dl>

<p>The functions refering to the XGBoost model can be found at Learning/xgboost.jl.</p>
</div>
</div>
<div class="section" id="data-treatment-pipeline">
<h3>Data Treatment Pipeline<a class="headerlink" href="#data-treatment-pipeline" title="Permalink to this headline">¶</a></h3>
<p>A pipeline consists of a model, a loss function, and data transformations, along with the
choice of wether to compute the loss function in the original space or in the transformed one.
The data transformations are operations to be applied to both the feature and target before they
are fed to the model. If the original_space option is true, they are transformed back before the
loss is computed, if not, the loss is computed right on the model output.</p>
<div class="section" id="data-transforms">
<h4>Data Transforms<a class="headerlink" href="#data-transforms" title="Permalink to this headline">¶</a></h4>
<p>Data Transforms also make use of the Julia Language inheritance capability. The abstrac base class
AbstractTransform implements the methods</p>
<dl class="py function">
<dt>
<code class="sig-name descname">fit!(transform&lt;:AbstractTransform, x)</code></dt>
<dd><p>Fits the given transform to the dataset x. Eg. calculates coeffs for PCA, mean and stds
for normalization, etc…</p>
</dd></dl>

<dl class="py function">
<dt id="apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">transform&lt;:AbstractTransform</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the fitted transform to x, returning the result</p>
</dd></dl>

<dl class="py function">
<dt id="reverse">
<code class="sig-name descname">reverse</code><span class="sig-paren">(</span><em class="sig-param">transform&lt;:AbstractTransform</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#reverse" title="Permalink to this definition">¶</a></dt>
<dd><p>Reverse the transformatio in x, returning the result</p>
</dd></dl>

<p>When those functions are implemented for a new transform, it can use</p>
<dl class="py function">
<dt>
<code class="sig-name descname">fit_apply!(transform&lt;:AbstractTransform, x)</code></dt>
<dd><p>Fit and apply the transform to x</p>
</dd></dl>

<p>The implemented transforms avaiables are the NormTransform and the IdTransform.
They can be found at Learning/tranforms.jl</p>
</div>
<div class="section" id="pipeline-methods">
<h4>Pipeline Methods<a class="headerlink" href="#pipeline-methods" title="Permalink to this headline">¶</a></h4>
<p>A pipeline has the methods</p>
<ul class="simple">
<li><p>train!(pipe::Pipeline, x, y)</p></li>
<li><p>predict(pipe::Pipeline, x)</p></li>
<li><p>loss(pipe::Pipeline, x, y)</p></li>
<li><p>getmodel(pipe::Pipeline)</p></li>
<li><p>crossvalidation!(pipe::Pipeline, x, y; k=5)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="putting-it-all-together">
<h2>Putting it all Together<a class="headerlink" href="#putting-it-all-together" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../scoringfunction/scoringfunction.html" class="btn btn-neutral float-right" title="Predictability Scoring Function" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../simulating/simulating.html" class="btn btn-neutral" title="Simulating Random and Predictable Signals" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, rodrigocorbelli@gmail.com.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/language_data.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script type="text/javascript" src="../_static/jquery.fancybox.min.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
  <script type="text/javascript">
    $(function(){
      $('.image-reference').fancybox();
    })
  </script>

</body>
</html>